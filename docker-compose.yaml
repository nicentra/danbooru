# A Docker Compose file that launches a minimal Danbooru instance. This is
# suitable as a quick demo or for personal use, not for public-facing sites.
#
# This will start a Danbooru instance running on http://localhost:3000.
#
# Usage:
#
#  docker-compose up
#  docker-compose down
#
# References:
#
# * https://docs.docker.com/get-docker/
# * https://docs.docker.com/compose/install/
# * https://docs.docker.com/compose/compose-file/compose-versioning
# * https://docs.docker.com/compose/release-notes

# Version 3.4 is the latest version that is supported by the version of Docker
# Compose shipped with Ubuntu 18.04 LTS (version 1.17.4).
version: "3.4"

services:
  danbooru:
    user: root
    # image: ghcr.io/danbooru/danbooru:production
    build: .
    ports:
      - "3000:3000"
    environment:
      # - RAILS_ENV=production
      - RAILS_SERVE_STATIC_FILES=true
      - PUMA_WORKERS=1
      - DATABASE_URL=postgresql://danbooru@postgres/danbooru
      - DANBOORU_REDIS_URL=redis://redis:6379
      - DANBOORU_IQDB_URL=http://iqdb:5588
      - DANBOORU_AUTOTAGGER_URL=http://autotagger:5000
      - DANBOORU_HOSTNAME=nbooru.dai
      - DANBOORU_CANONICAL_URL=http://nbooru.dai
    volumes:
      - "danbooru-images:/danbooru/public/data"
    tmpfs:
      - /tmp
    depends_on:
      - postgres
      - iqdb
      - autotagger
    command: ["bash", "-c", "bin/rails db:prepare && bin/rails db:seed && bin/rails server -b 0.0.0.0"]

  cron:
    user: root
    # image: ghcr.io/danbooru/danbooru:production
    build: .
    environment:
      # - RAILS_ENV=production
      - DATABASE_URL=postgresql://danbooru@postgres/danbooru
      - DANBOORU_REDIS_URL=redis://redis:6379
      - DANBOORU_IQDB_URL=http://iqdb:5588
      - DANBOORU_AUTOTAGGER_URL=http://autotagger:5000
      - DANBOORU_HOSTNAME=nbooru.dai
      - DANBOORU_CANONICAL_URL=http://nbooru.dai
    depends_on:
      - danbooru
    volumes:
      - "danbooru-images:/danbooru/public/data"
    command: ["bash", "-c", "bin/wait-for-http http://nbooru.dai:3000 5s && bin/rails danbooru:cron"]

  jobs:
    # We need root to write temp upload files in the images directory (/danbooru/public/data)
    user: root
    # image: ghcr.io/danbooru/danbooru:production
    build: .
    environment:
      # - RAILS_ENV=production
      - DATABASE_URL=postgresql://danbooru@postgres/danbooru
      - DANBOORU_REDIS_URL=redis://redis:6379
      - DANBOORU_IQDB_URL=http://iqdb:5588
      - DANBOORU_AUTOTAGGER_URL=http://autotagger:5000
      - DANBOORU_HOSTNAME=nbooru.dai
      - DANBOORU_CANONICAL_URL=http://nbooru.dai
    depends_on:
      - danbooru
    volumes:
      # We need access to images so we can add/remove images to IQDB.
      - "danbooru-images:/danbooru/public/data"
    command: ["bash", "-c", "bin/wait-for-http http://nbooru.dai:3000 5s && bin/good_job start"]

  # https://github.com/danbooru/iqdb
  # https://hub.docker.com/repository/docker/evazion/iqdb
  iqdb:
    image: ghcr.io/danbooru/iqdb/iqdb:latest
    volumes:
      - "iqdb-data:/iqdb/data"
    command: ["listen", "0.0.0.0:5588", "/iqdb/data/iqdb.sqlite"]

  autotagger:
    image: ghcr.io/danbooru/autotagger:latest
    ports:
      - "5000:5000"

  redis:
    image: redis

  postgres:
    image: ghcr.io/danbooru/postgres:14.1
    environment:
      POSTGRES_USER: danbooru
      POSTGRES_HOST_AUTH_METHOD: trust
    volumes:
      - "danbooru-data:/var/lib/postgresql/data"

volumes:
  danbooru-images:
    name: danbooru-images
  danbooru-data:
    name: danbooru-data
  iqdb-data:
    name: iqdb-data